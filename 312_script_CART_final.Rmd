---
title: "ST312 SVMs"
date: "2025-03-16"
output: html_document
---

```{r}
rm(list = ls())
library(e1071)
library(caret)
library(dplyr)
set.seed(123)
setwd("C:/Users/aodha/OneDrive - London School of Economics/ST312")
data <- read.csv("new_data.csv")


```



```{r}
set.seed(123)
# Load libraries
library(rpart)
library(rpart.plot)
library(caret)



# Create success variable
data$success <- as.factor(ifelse(data$state == TRUE, "Yes", "No"))

# Subset relevant columns with new predictors
# Note subcategory is not included 
df_full <- data[, c("success", "goal_usd", "campaign_duration", "staff_pick", 
                    "category", "backers_count", "video", 
                    "converted_pledged_amount", "country_displayable_name",
                    "currency", "year_launched", "desired_duration",
                     "blurb_characters", "month_launched", "day_launched")]



# Convert categorical variables to factors
df_full$staff_pick <- as.factor(df_full$staff_pick)
df_full$category <- as.factor(df_full$category)
df_full$video <- as.factor(df_full$video)
df_full$country_displayable_name <- as.factor(df_full$country_displayable_name)
df_full$currency <- as.factor(df_full$currency)
df_full$month_launched <- as.factor(df_full$month_launched)
df_full$day_launched <- as.factor(df_full$day_launched)
df_full$year_launched <- as.factor(df_full$year_launched)

# Split into train/test
set.seed(123)
train_index_full <- createDataPartition(df_full$success, p = 0.8, list = FALSE)
train_data_full <- df_full[train_index_full, ]
test_data_full <- df_full[-train_index_full, ]

# Build the CART model with a lower bound cp
cart_model_full <- rpart(
  success ~ .,
  data = train_data_full,
  method = "class",
  control = rpart.control(minsplit = 20, cp = 0.0001)  # allow deep tree for pruning flexibility
)

# Print CP table to inspect options
printcp(cart_model_full)

# pune the tree using **manual cp = 0.01**
pruned_model_manual <- prune(cart_model_full, cp = 0.01)

# Visualize pruned tree
rpart.plot(pruned_model_manual, box.palette = "auto", shadow.col = "gray", nn = TRUE, tweak = 1.4, fallen.leaves = TRUE)


# Predict on test set
predictions_manual <- predict(pruned_model_manual, test_data_full, type = "class")

# Evaluate with confusion matrix
confusion_matrix_manual <- confusionMatrix(predictions_manual, test_data_full$success)
print(confusion_matrix_manual)

# Show variable importance
print(pruned_model_manual$variable.importance)


```


```{r}
set.seed(123)
# Load libraries
library(rpart)
library(rpart.plot)
library(caret)

# Build the initial complex tree (assuming data preparation is already done)
cart_model_full <- rpart(
  success ~ .,
  data = train_data_full,
  method = "class",
  control = rpart.control(minsplit = 20, cp = 0.0001)  # low CP to allow deep tree
)

# Get CP table
cp_table_full <- printcp(cart_model_full)
print("Cost Complexity Pruning Table:")
print(cp_table_full)

# Method 1: Manual CP selection
manual_cp <- 0.01
pruned_model_manual <- prune(cart_model_full, cp = manual_cp)
cat("\n\nMethod 1: Manual CP Selection (CP =", manual_cp, ")\n")
cat("Number of splits:", sum(pruned_model_manual$frame$var == "<leaf>") - 1, "\n")

# Method 2: Minimum xerror
min_xerror_index <- which.min(cp_table_full[, "xerror"])
min_xerror_cp <- cp_table_full[min_xerror_index, "CP"]
pruned_model_min_xerror <- prune(cart_model_full, cp = min_xerror_cp)
cat("\n\nMethod 2: Minimum Cross-Validation Error\n")
cat("Selected CP:", min_xerror_cp, "\n")
cat("Minimum xerror:", cp_table_full[min_xerror_index, "xerror"], "\n")
cat("Number of splits:", cp_table_full[min_xerror_index, "nsplit"], "\n")

# Method 3: One Standard Error Rule
min_xerror <- min(cp_table_full[, "xerror"])
min_xerror_se <- cp_table_full[min_xerror_index, "xstd"]
threshold <- min_xerror + min_xerror_se
eligible_rows <- which(cp_table_full[, "xerror"] <= threshold)
best_cp_index <- min(eligible_rows)  # Get the largest CP value (simplest model)
one_se_cp <- cp_table_full[best_cp_index, "CP"]
pruned_model_one_se <- prune(cart_model_full, cp = one_se_cp)
cat("\n\nMethod 3: One Standard Error Rule\n")
cat("Minimum xerror:", min_xerror, "\n")
cat("Standard error at minimum:", min_xerror_se, "\n")
cat("1-SE Threshold:", threshold, "\n")
cat("Selected CP using 1-SE rule:", one_se_cp, "\n")
cat("Number of splits:", cp_table_full[best_cp_index, "nsplit"], "\n")

# Compare performance on test data
predictions_manual <- predict(pruned_model_manual, test_data_full, type = "class")
predictions_min_xerror <- predict(pruned_model_min_xerror, test_data_full, type = "class")
predictions_one_se <- predict(pruned_model_one_se, test_data_full, type = "class")

# Calculate confusion matrices
conf_matrix_manual <- confusionMatrix(predictions_manual, test_data_full$success)
conf_matrix_min_xerror <- confusionMatrix(predictions_min_xerror, test_data_full$success)
conf_matrix_one_se <- confusionMatrix(predictions_one_se, test_data_full$success)

# Print comparison summary
cat("\n\nPerformance Comparison:\n")
cat("Manual CP (", manual_cp, "): Accuracy =", conf_matrix_manual$overall["Accuracy"], "\n")
cat("Min Xerror CP (", min_xerror_cp, "): Accuracy =", conf_matrix_min_xerror$overall["Accuracy"], "\n")
cat("One-SE Rule CP (", one_se_cp, "): Accuracy =", conf_matrix_one_se$overall["Accuracy"], "\n")

# Visualize all three trees (optional)
par(mfrow=c(1,3))
rpart.plot(pruned_model_manual, main="Manual CP", tweak=1.2)
rpart.plot(pruned_model_min_xerror, main="Min Xerror", tweak=1.2)
rpart.plot(pruned_model_one_se, main="One-SE Rule", tweak=1.2)
par(mfrow=c(1,1))

# Variable importance comparison
cat("\n\nTop 5 Important Variables (Manual CP):\n")
var_imp_manual <- head(sort(pruned_model_manual$variable.importance, decreasing=TRUE), 5)
print(var_imp_manual)

cat("\nTop 5 Important Variables (Min Xerror):\n")
var_imp_min_xerror <- head(sort(pruned_model_min_xerror$variable.importance, decreasing=TRUE), 5)
print(var_imp_min_xerror)

cat("\nTop 5 Important Variables (One-SE Rule):\n")
var_imp_one_se <- head(sort(pruned_model_one_se$variable.importance, decreasing=TRUE), 5)
print(var_imp_one_se)

# As we can see from the tree plot, the 2 selecgtion does not give us an interpretable tree
```


```{r}
rm(list = ls())
set.seed(123)
setwd("C:/Users/aodha/OneDrive - London School of Economics/ST312")
data <- read.csv("new_data.csv")
# Now lets build a regression tree model where the outcome is converted pledged amount
# Create a new dataframe excluding the outcome variable from predictors



df_regression <- data[, c("goal_usd", "campaign_duration", "staff_pick", 
                         "category", "backers_count", "video", 
                         "converted_pledged_amount", "country_displayable_name",
                         "currency", "year_launched", "desired_duration",
                          "blurb_characters", "month_launched", "day_launched")]



# Convert categorical variables to factors
factor_vars <- c("staff_pick", "category", "video",
                 "country_displayable_name", "currency",
                 "month_launched", "day_launched", "year_launched")
df_regression[factor_vars] <- lapply(df_regression[factor_vars], as.factor)

# Split data into training and testing sets
set.seed(123)
train_index_reg <- createDataPartition(df_regression$converted_pledged_amount, p = 0.8, list = FALSE)
train_data_reg  <- df_regression[train_index_reg, ]
test_data_reg   <- df_regression[-train_index_reg, ]

# Build the full regression tree
cart_model_reg <- rpart(
  converted_pledged_amount ~ .,
  data    = train_data_reg,
  method  = "anova",
  control = rpart.control(minsplit = 20, cp = 0.0001)
)

# (Optional) Inspect the CP table
#printcp(cart_model_reg)

# Prune the tree at a fixed complexity parameter of 0.01
pruned_model_reg <- prune(cart_model_reg, cp = 0.01)

# Visualize the pruned tree
rpart.plot(
  pruned_model_reg,
  box.palette    = "auto",
  shadow.col     = "gray",
  nn             = TRUE,
  tweak          = 2,
  fallen.leaves  = TRUE
)

# Predict on test data
predictions_reg <- predict(pruned_model_reg, test_data_reg)

# Calculate performance metrics
rmse     <- sqrt(mean((predictions_reg - test_data_reg$converted_pledged_amount)^2))
mae      <- mean(abs(predictions_reg - test_data_reg$converted_pledged_amount))
r_squared <- 1 - sum((test_data_reg$converted_pledged_amount - predictions_reg)^2) /
                  sum((test_data_reg$converted_pledged_amount - 
                       mean(test_data_reg$converted_pledged_amount))^2)

# Print performance metrics
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("R-squared:", r_squared, "\n")

# Variable importance
variable_importance_reg <- pruned_model_reg$variable.importance
print(variable_importance_reg)

# (Optional) Scatter plot of predicted vs actual values
plot(
  test_data_reg$converted_pledged_amount,
  predictions_reg,
  xlab = "Actual Pledged Amount",
  ylab = "Predicted Pledged Amount",
  main = "Predicted vs Actual Pledged Amounts"
)
abline(0, 1, col = "red")

```
```{r}
# Now lets do the same for backers count
rm(list = ls())
set.seed(123)
setwd("C:/Users/aodha/OneDrive - London School of Economics/ST312")
data <- read.csv("new_data.csv")



# Build dataframe
df_backers <- data[, c("goal_usd", "campaign_duration", "staff_pick", 
                       "category", "video", "converted_pledged_amount",
                       "country_displayable_name", "currency", "year_launched",
                       "desired_duration", "blurb_characters",
                       "month_launched", "day_launched", "backers_count")]


# Convert categoricals at once
factor_vars <- c("staff_pick", "category", "video",
                 "country_displayable_name", "currency",
                 "year_launched", "month_launched", "day_launched")
df_backers[factor_vars] <- lapply(df_backers[factor_vars], as.factor)

# Train/test split
set.seed(123)
train_index_backers <- createDataPartition(df_backers$backers_count, p = 0.8, list = FALSE)
train_data_backers <- df_backers[train_index_backers, ]
test_data_backers  <- df_backers[-train_index_backers, ]

# Build the full regression tree
cart_model_backers <- rpart(
  backers_count ~ .,
  data    = train_data_backers,
  method  = "anova",
  control = rpart.control(minsplit = 20, cp = 0.0001)
)

# (Optional) inspect the full CP table
#printcp(cart_model_backers)

# Prune at cp = 0.01
pruned_model_backers <- prune(cart_model_backers, cp = 0.01)

# Visualize the pruned tree
rpart.plot(
  pruned_model_backers,
  box.palette    = "auto",
  shadow.col     = "gray",
  nn             = TRUE,
  tweak          = 1,
  fallen.leaves  = TRUE
)

# Predict on test set
predictions_backers <- predict(pruned_model_backers, test_data_backers)

# Performance metrics
rmse     <- sqrt(mean((predictions_backers - test_data_backers$backers_count)^2))
mae      <- mean(abs(predictions_backers - test_data_backers$backers_count))
r_squared <- 1 - sum((test_data_backers$backers_count - predictions_backers)^2) /
                  sum((test_data_backers$backers_count - 
                       mean(test_data_backers$backers_count))^2)

cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("R-squared:", r_squared, "\n")

# Variable importance
print(pruned_model_backers$variable.importance)

# (Optional) CP table again
#printcp(cart_model_backers)

# Scatter plot: actual vs. predicted
plot(
  test_data_backers$backers_count,
  predictions_backers,
  xlab = "Actual Backers Count",
  ylab = "Predicted Backers Count",
  main = "Predicted vs Actual Backers Count"
)
abline(0, 1, col = "red")

```
```{r}
# Now we will build a classfication tree without the 2 main predictors
set.seed(123)
rm(list = ls())
set.seed(123)
setwd("C:/Users/aodha/OneDrive - London School of Economics/ST312")
data <- read.csv("new_data.csv")
# Create success variable
data$success <- as.factor(ifelse(data$state == TRUE, "Yes", "No"))

# Subset relevant columns with new predictors
df_1 <- data[, c("success", "goal_usd", "campaign_duration", "staff_pick", 
                    "category", "video", 
                    "country_displayable_name",
                    "currency", "year_launched", "desired_duration",
                     "blurb_characters", "month_launched", "day_launched")]




# Convert categorical variables to factors
df_1$staff_pick <- as.factor(df_1$staff_pick)
df_1$category <- as.factor(df_1$category)

df_1$video <- as.factor(df_1$video)
df_1$country_displayable_name <- as.factor(df_1$country_displayable_name)
df_1$currency <- as.factor(df_1$currency)
df_1$month_launched <- as.factor(df_1$month_launched)
df_1$day_launched <- as.factor(df_1$day_launched)
df_1$year_launched <- as.factor(df_1$year_launched)

# Split into train/test
set.seed(123)
train_index_1 <- createDataPartition(df_1$success, p = 0.8, list = FALSE)
train_data_1 <- df_1[train_index_1, ]
test_data_1 <- df_1[-train_index_1, ]

# Build the CART model with a lower bound cp
cart_model_1 <- rpart(
  success ~ .,
  data = train_data_1,
  method = "class",
  control = rpart.control(minsplit = 20, cp = 0.0001)  # allow deep tree for pruning flexibility
)


# pune the tree using **manual cp = 0.01**
pruned_model_1 <- prune(cart_model_1, cp = 0.01)

# Visualize pruned tree
rpart.plot(pruned_model_1, box.palette = "auto", shadow.col = "gray", nn = TRUE, tweak = 1.8, fallen.leaves = TRUE)


# Predict on test set
predictions_1 <- predict(pruned_model_1, test_data_1, type = "class")

# Evaluate with confusion matrix
confusion_matrix_1 <- confusionMatrix(predictions_1, test_data_1$success)
print(confusion_matrix_1)

# Show variable importance
print(pruned_model_1$variable.importance)



```
```{r}
# predicting backers count without converted pledged amount
# Build dataframe
set.seed(123)
rm(list = ls())
setwd("C:/Users/aodha/OneDrive - London School of Economics/ST312")
data <- read.csv("new_data.csv")

df_backers <- data[, c("goal_usd", "campaign_duration", "staff_pick", 
                       "category", "video","country_displayable_name", "currency", "year_launched",
                       "desired_duration", "blurb_characters",
                       "month_launched", "day_launched", "backers_count")]

# Handle missing values
df_backers <- na.omit(df_backers)

# Convert categoricals at once
factor_vars <- c("staff_pick", "category", "video",
                 "country_displayable_name", "currency",
                 "year_launched", "month_launched", "day_launched")
df_backers[factor_vars] <- lapply(df_backers[factor_vars], as.factor)

# Train/test split
set.seed(123)
train_index_backers <- createDataPartition(df_backers$backers_count, p = 0.8, list = FALSE)
train_data_backers <- df_backers[train_index_backers, ]
test_data_backers  <- df_backers[-train_index_backers, ]

# Build the full regression tree
cart_model_backers <- rpart(
  backers_count ~ .,
  data    = train_data_backers,
  method  = "anova",
  control = rpart.control(minsplit = 20, cp = 0.0001)
)

# (Optional) inspect the full CP table
# printcp(cart_model_backers)

# Prune at cp = 0.01
pruned_model_backers <- prune(cart_model_backers, cp = 0.01)

# Visualize the pruned tree
rpart.plot(
  pruned_model_backers,
  box.palette    = "auto",
  shadow.col     = "gray",
  nn             = TRUE,
  tweak          = 1,
  fallen.leaves  = TRUE
)

# Predict on test set
predictions_backers <- predict(pruned_model_backers, test_data_backers)

# Performance metrics
rmse     <- sqrt(mean((predictions_backers - test_data_backers$backers_count)^2))
mae      <- mean(abs(predictions_backers - test_data_backers$backers_count))
r_squared <- 1 - sum((test_data_backers$backers_count - predictions_backers)^2) /
                  sum((test_data_backers$backers_count - 
                       mean(test_data_backers$backers_count))^2)

cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("R-squared:", r_squared, "\n")

# Variable importance
print(pruned_model_backers$variable.importance)



# Scatter plot: actual vs. predicted
plot(
  test_data_backers$backers_count,
  predictions_backers,
  xlab = "Actual Backers Count",
  ylab = "Predicted Backers Count",
  main = "Predicted vs Actual Backers Count"
)
abline(0, 1, col = "red")

```

```{r}
rm(list = ls())
set.seed(123)
setwd("C:/Users/aodha/OneDrive - London School of Economics/ST312")
data <- read.csv("new_data.csv")
# predicting converted pledged amount without backers count



df_regression <- data[, c("goal_usd", "campaign_duration", "staff_pick", 
                         "category", "video", 
                         "converted_pledged_amount", "country_displayable_name",
                         "currency", "year_launched", "desired_duration",
                          "blurb_characters", "month_launched", "day_launched")]

# Handle missing values
df_regression <- na.omit(df_regression)

# Convert categorical variables to factors
factor_vars <- c("staff_pick", "category", "video",
                 "country_displayable_name", "currency",
                 "month_launched", "day_launched", "year_launched")
df_regression[factor_vars] <- lapply(df_regression[factor_vars], as.factor)

# Split data into training and testing sets
set.seed(123)
train_index_reg <- createDataPartition(df_regression$converted_pledged_amount, p = 0.8, list = FALSE)
train_data_reg  <- df_regression[train_index_reg, ]
test_data_reg   <- df_regression[-train_index_reg, ]

# Build the full (overgrown) regression tree
cart_model_reg <- rpart(
  converted_pledged_amount ~ .,
  data    = train_data_reg,
  method  = "anova",
  control = rpart.control(minsplit = 20, cp = 0.0001)
)

# (Optional) Inspect the CP table
#printcp(cart_model_reg)

# Prune the tree at a fixed complexity parameter of 0.01
pruned_model_reg <- prune(cart_model_reg, cp = 0.01)

# Visualize the pruned tree
rpart.plot(
  pruned_model_reg,
  box.palette    = "auto",
  shadow.col     = "gray",
  nn             = TRUE,
  tweak          = 2,
  fallen.leaves  = TRUE
)

# Predict on test data
predictions_reg <- predict(pruned_model_reg, test_data_reg)

# Calculate performance metrics
rmse     <- sqrt(mean((predictions_reg - test_data_reg$converted_pledged_amount)^2))
mae      <- mean(abs(predictions_reg - test_data_reg$converted_pledged_amount))
r_squared <- 1 - sum((test_data_reg$converted_pledged_amount - predictions_reg)^2) /
                  sum((test_data_reg$converted_pledged_amount - 
                       mean(test_data_reg$converted_pledged_amount))^2)

# Print performance metrics
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("R-squared:", r_squared, "\n")

# Variable importance
variable_importance_reg <- pruned_model_reg$variable.importance
print(variable_importance_reg)


```




